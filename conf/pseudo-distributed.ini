[desktop]
  # Set this to a random string, the longer the better.
  # This is used for secure hashing in the session store.
  secret_key=abcd1234

  # Execute this script to produce the Django secret key. This will be used when
  # 'secret_key' is not set.
  ## secret_key_script=

  # Webserver listens on this address and port
  http_host=0.0.0.0
  http_port=8000
  [[database]]
    engine=mysql
    host=localhost
    name=hue
    password=
    port=3306
    user=hue
[hadoop]
# the path where Hadoop is installed
home=/usr/local/hadoop
# Path to libhdfs.so file (or libhdfs3.so if using Hadoop3)
libhdfs_dir=/usr/local/hadoop/lib/native/
# Configure these values to match your environment.
fs_defaultfs=hdfs://localhost:9000
mapred_job_tracker=localhost:9001
security_enabled=false
[[yarn_clusters]]
    [[[default]]]
    # Enter the host on which you are running the ResourceManager
    resourcemanager_host=localhost     
    # Whether to submit jobs to this cluster
    submit_to=True
    # URL of the ResourceManager API
    resourcemanager_api_url=http://localhost:8088
    # URL of the ProxyServer API
    proxy_api_url=http://localhost:8088
    # URL of the HistoryServer API
    history_server_api_url=http://localhost:19888

[hive]
# the path where Hive is installed
home=/usr/local/hive

[beeswax]
# Host where HiveServer2 is running.
hive_server_host=localhost

[oozie]
# the path where Oozie is installed
home=/usr/local/oozie

[liboozie]
# The URL where the Oozie service runs on.
oozie_home_dir=/usr/local/oozie/
# These should match the values in your Oozie configuration.
oozie_http_url=http://localhost:11000/oozie
oozie_database=oozie
oozie_username=oozie
oozie_password=
# This should match the value of the sharelib property in your Oozie configuration.
oozie_sharelib=/usr/local/oozie/share/lib

[spark]
# the path where Spark is installed
home=/usr/local/spark

[zookeeper]
# the path where ZooKeeper is installed
home=/usr/local/zookeeper

[hbase]
# the path where HBase is installed
home=/usr/local/hbase

[mapreduce]
# the path where MapReduce is installed
home=/usr/local/hadoop

[sqoop]
# the path where Sqoop is installed
home=/usr/local/sqoop

# Hadoop configuration properties
[hadoop_conf]
# Hadoop configuration directory
conf_dir=/usr/local/hadoop/etc/hadoop

# Hadoop executables
[hadoop_exec]
# Hadoop executable paths
sbin_dir=/usr/local/hadoop/sbin
bin_dir=/usr/local/hadoop/bin

# Hive configuration properties
[hive_conf]
# Hive configuration directory
conf_dir=/usr/local/hive/conf

# Hive executables
[hive_exec]
# Hive executable paths
bin_dir=/usr/local/hive/bin

# Oozie configuration properties
[oozie_conf]
# Oozie configuration directory
conf_dir=/usr/local/oozie/conf

# Oozie executables
[oozie_exec]
# Oozie executable paths
bin_dir=/usr/local/oozie/bin

# Spark configuration properties
[spark_conf]
# Spark configuration directory
conf_dir=/usr/local/spark/conf

# Spark executables
[spark_exec]
# Spark executable paths
sbin_dir=/usr/local/spark/sbin
bin_dir=/usr/local/spark/bin

# ZooKeeper configuration properties
[zookeeper_conf]
# ZooKeeper configuration directory
conf_dir=/usr/local/zookeeper/conf

# ZooKeeper executables
[zookeeper_exec]
# ZooKeeper executable paths
bin_dir=/usr/local/zookeeper/bin

# HBase configuration properties
[hbase_conf]
# HBase configuration directory
conf_dir=/usr/local/hbase/conf

# HBase executables
[hbase_exec]
# HBase executable paths
sbin_dir=/usr/local/hbase/bin
bin_dir=/usr/local/hbase/bin

# MapReduce configuration properties
[mapreduce_conf]
# MapReduce configuration directory
conf_dir=/usr/local/hadoop/etc/hadoop

# MapReduce executables
[mapreduce_exec]
# MapReduce executable paths
sbin_dir=/usr/local/hadoop/sbin
bin_dir=/usr/local/hadoop/bin

# Sqoop configuration properties
[sqoop_conf]
# Sqoop configuration directory
conf_dir=/usr/local/sqoop/conf

# Sqoop executables
[sqoop_exec]
# Sqoop executable paths
bin_dir=/usr/local/sqoop/bin
